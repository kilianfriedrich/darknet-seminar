{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "Leak Sites Indexing Tool\n",
    "========================\n",
    "\n",
    "Dieses Jupyter-Notebook scraped verschiedene Ressourcen, die Leak Sites sammeln, und vergleicht ihre Inhalte.\n",
    "\n",
    "Voraussetzungen\n",
    "---------------\n",
    "\n",
    "Um die Verfügbarkeit von Leak Sites zu prüfen, wird ein Tor-Proxy benötigt.\n",
    "\n",
    "Unter Linux kann dafür das Tor-Programm installiert und mit `systemctl start tor` werden.\n",
    "Dann läuft auf dem Port 9050 ein lokaler Tor-Socks-Proxy, über den dieses Notebook Onion-Links aufrufen kann.\n",
    "Wenn der Tor-Proxy anders zur Verfügung gestellt wird, kann hier auch eine andere Proxy-Adresse konfiguriert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e333053ff0563844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:44:16.728667Z",
     "start_time": "2024-12-17T20:44:16.726171Z"
    }
   },
   "outputs": [],
   "source": [
    "tor_proxy = 'socks5h://localhost:9050'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2488d31c596346",
   "metadata": {},
   "source": [
    "Proxy-Test\n",
    "----------\n",
    "\n",
    "Die Ausgabe der nächsten Zelle sollte \"✅ You are using Tor!\" sein, ansonsten können Onion-Seiten nicht aufgerufen werden.\n",
    "Dann werden alle Leak Sites fälschlicherweise als Offline angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9140457caed5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T20:44:17.971537Z",
     "start_time": "2024-12-17T20:44:17.417206Z"
    }
   },
   "outputs": [],
   "source": [
    "from requests import session, get\n",
    "\n",
    "tor = session()\n",
    "tor.proxies.update({'http': tor_proxy, 'https': tor_proxy})\n",
    "\n",
    "resp = tor.get('https://check.torproject.org', timeout=60)\n",
    "if 'Congratulations. This browser is configured to use Tor.' in resp.text:\n",
    "    print('✅ You are using Tor!')\n",
    "else:\n",
    "    print('❌ You are NOT using Tor!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8917249de37bf",
   "metadata": {},
   "source": [
    "# [fastfire/deepdarkCTI](https://github.com/fastfire/deepdarkCTI/blob/main/ransomware_gang.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:59:44.704991468Z",
     "start_time": "2024-12-17T19:55:09.657108Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "deepdarkcti_md = get('https://raw.githubusercontent.com/fastfire/deepdarkCTI/refs/heads/main/ransomware_gang.md', timeout=60).text\n",
    "lines = deepdarkcti_md.splitlines()\n",
    "lines.pop(1) # Header-Endzeile entfernen\n",
    "lines = [line.strip('|') for line in lines] # '|' Am Anfang und Ende der Zeile entfernen\n",
    "\n",
    "deepdarkcti_reader = csv.DictReader(lines, delimiter='|')\n",
    "\n",
    "deepdarkcti = { 'Group': [], 'Link': [], 'Available': [], 'AvailableLabel': [] }\n",
    "for row in deepdarkcti_reader:\n",
    "    parsed_name = re.search(r\"\\[([^]]*)]\\(([^)]*)\\)\", row['Name'])\n",
    "    if parsed_name is not None:\n",
    "        if parsed_name.group(1) in [\n",
    "            'Ransomfeed',\n",
    "            'eCrime Services',\n",
    "            'RANSOM DB',\n",
    "            'RANSOMWARE GROUP SITES (list)',\n",
    "            'RANSOMWARE GROUPS MONITORING TOOL',\n",
    "            'RansomChats'\n",
    "        ]:\n",
    "            continue\n",
    "        deepdarkcti['Group'].append(parsed_name.group(1))\n",
    "        deepdarkcti['Link'].append(parsed_name.group(2))\n",
    "        deepdarkcti['AvailableLabel'].append('ONLINE' in row['Status'])\n",
    "        print(f\"Checking {parsed_name.group(1)} ({parsed_name.group(2)})\")\n",
    "        try:\n",
    "            tor.get(parsed_name.group(2), timeout=60)\n",
    "            deepdarkcti['Available'].append(True)\n",
    "        except:\n",
    "            deepdarkcti['Available'].append(False)\n",
    "        \n",
    "deepdarkcti = pd.DataFrame(deepdarkcti)\n",
    "deepdarkcti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d844dee14be87f02",
   "metadata": {},
   "source": [
    "# [u/DrinkMoreCodeMore](https://www.reddit.com/r/Malware/comments/1bpcrdw/list_of_ransomware_groups_and_their_pr_pages_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e58a1b7e04493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:58:44.505182Z",
     "start_time": "2024-12-17T19:55:14.188509Z"
    }
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "reddit2024_soup = bs4.BeautifulSoup(get('https://www.reddit.com/r/Malware/comments/1bpcrdw/list_of_ransomware_groups_and_their_pr_pages_2024/', timeout=60).text)\n",
    "reddit2024_soup = reddit2024_soup.css.select('shreddit-post [slot=text-body] > div > div > p')\n",
    "\n",
    "reddit2024 = { 'Group': [], 'Link': [], 'Available': [] }\n",
    "for p in reddit2024_soup:\n",
    "    if p.find('a') is None:\n",
    "        continue\n",
    "    parsed_text = re.search(r\"([^]]*) - ([^)]*)\", p.text)\n",
    "    if parsed_text is not None:\n",
    "        reddit2024['Group'].append(parsed_text.group(1).strip())\n",
    "        reddit2024['Link'].append(parsed_text.group(2).strip())\n",
    "        print(f\"Checking {parsed_text.group(1).strip()} ({parsed_text.group(2).strip()})\")\n",
    "        try:\n",
    "            tor.get(parsed_text.group(2).strip(), timeout=60)\n",
    "            reddit2024['Available'].append(True)\n",
    "        except:\n",
    "            reddit2024['Available'].append(False)\n",
    "            \n",
    "reddit2024 = pd.DataFrame(reddit2024)\n",
    "reddit2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e29c2c994ac475",
   "metadata": {},
   "source": [
    "# [Onion-Seite](http://ransomwr3tsydeii4q43vazm7wofla5ujdajquitomtd47cxjtfgwyyd.onion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7289e9687a034",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-17T19:58:44.556255Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "darknet_soup = bs4.BeautifulSoup(tor.get('http://ransomwr3tsydeii4q43vazm7wofla5ujdajquitomtd47cxjtfgwyyd.onion/', timeout=60).text)\n",
    "darknet_soup = darknet_soup.css.select_one('.table .table-body')\n",
    "darknet_soup = darknet_soup.css.select('.table-row')\n",
    "\n",
    "darknet = { 'Group': [], 'Link': [], 'Available': [] }\n",
    "for row in darknet_soup:\n",
    "    name = row.css.select_one('.table-cell')\n",
    "    links = row.css.select('a')\n",
    "    for link in links:\n",
    "        darknet['Group'].append(name.text)\n",
    "        darknet['Link'].append(link.attrs['href'])\n",
    "        print(f\"Checking {name.text} ({link.attrs['href']})\")\n",
    "        try:\n",
    "            tor.get(link.attrs['href'], timeout=60)\n",
    "            darknet['Available'].append(True)\n",
    "        except:\n",
    "            darknet['Available'].append(False)\n",
    "\n",
    "darknet = pd.DataFrame(darknet)\n",
    "darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda694183670671",
   "metadata": {},
   "source": [
    "# [Ransomwatch](https://ransomwatch.telemetry.ltd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ee970b278f0e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:59:44.640951574Z",
     "start_time": "2024-12-17T19:53:23.958648Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "ransomwatch_md = get('https://ransomwatch.telemetry.ltd/INDEX.md', timeout=60).text\n",
    "lines = ransomwatch_md.splitlines()[2:-1]\n",
    "lines.pop(1) # Header-Endzeile entfernen\n",
    "lines = [line.strip('|') for line in lines] # '|' Am Anfang und Ende der Zeile entfernen\n",
    "\n",
    "ransomwatch_reader = csv.DictReader(lines, delimiter='|')\n",
    "\n",
    "ransomwatch = { 'Group': [], 'Available': [], 'Link': [], 'AvailableLabel': [] }\n",
    "for row in ransomwatch_reader:\n",
    "    if len(row[' group '].strip()) == 0:\n",
    "        continue\n",
    "    parsed_name = re.search(r\"\\[([^]]*)]\\(([^)]*)\\)\", row[' group '])\n",
    "    ransomwatch['Group'].append(parsed_name.group(1))\n",
    "    ransomwatch['Link'].append(row[' location '])\n",
    "    if row[' status '] is not None:\n",
    "        ransomwatch['AvailableLabel'].append('🟢' in row[' status '])\n",
    "    else:\n",
    "        ransomwatch['AvailableLabel'].append(False)\n",
    "    print(f\"Checking {parsed_name.group(1)} ({row[' location ']})\")\n",
    "    try:\n",
    "        tor.get(row[' location '], timeout=60)\n",
    "        ransomwatch['Available'].append(True)\n",
    "    except:\n",
    "        ransomwatch['Available'].append(False)\n",
    "        \n",
    "    \n",
    "ransomwatch = pd.DataFrame(ransomwatch)\n",
    "ransomwatch['Available'] = ransomwatch['Available'].astype('bool')\n",
    "ransomwatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2edabb61dfa65b",
   "metadata": {},
   "source": [
    "# [Ransomfind](https://ransomfind.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4379e9425506254",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:59:44.654693729Z",
     "start_time": "2024-11-11T19:44:49.260928Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "ransomfind_md = get('https://ransomfind.io/INDEX.md', timeout=60).text\n",
    "lines = ransomfind_md.splitlines()[2:-1]\n",
    "lines.pop(1) # Header-Endzeile entfernen\n",
    "lines = [line.strip('|') for line in lines] # '|' Am Anfang und Ende der Zeile entfernen\n",
    "\n",
    "ransomfind_reader = csv.DictReader(lines, delimiter='|')\n",
    "\n",
    "ransomfind = { 'Group': [], 'Available': [], 'Link': [], 'AvailableLabel': [] }\n",
    "for row in ransomfind_reader:\n",
    "    parsed_name = re.search(r\"\\[([^]]*)]\\(([^)]*)\\)\", row[' group '])\n",
    "    ransomfind['Group'].append(parsed_name.group(1))\n",
    "    ransomfind['Link'].append(row[' location '].strip())\n",
    "    ransomfind['AvailableLabel'].append('🟢' in row[' status '])\n",
    "    print(f\"Checking {parsed_name.group(1)} ({row[' location '].strip()})\")\n",
    "    try:\n",
    "        tor.get(row[' location '].strip(), timeout=60)\n",
    "        ransomfind['Available'].append(True)\n",
    "    except:\n",
    "        ransomfind['Available'].append(False)\n",
    "\n",
    "ransomfind = pd.DataFrame(ransomfind)\n",
    "ransomfind['Available'] = ransomfind['Available'].astype('bool')\n",
    "ransomfind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a64ff14305e5db",
   "metadata": {},
   "source": [
    "# [Ransomlook](https://www.ransomlook.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02efe59833fa9a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:59:44.657423659Z",
     "start_time": "2024-11-11T19:44:51.375165Z"
    }
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "ransomlook_soup = bs4.BeautifulSoup(get('https://www.ransomlook.io/groups', timeout=60).text)\n",
    "\n",
    "ransomlook = { 'Group': [], 'Available': [], 'Link': [], 'AvailableLabel': [] }\n",
    "for header in ransomlook_soup.css.select('h3'):\n",
    "    following = header.find_next('div')\n",
    "    if following is not None:\n",
    "        links = following.css.select_one('tbody')\n",
    "        for link in links.css.select('tr'):\n",
    "            ransomlook['Group'].append(header.text)\n",
    "            ransomlook['Link'].append(link.css.select_one('td:nth-child(4)').text)\n",
    "            ransomlook['AvailableLabel'].append('⬆️' in link.css.select_one('td:nth-child(2)').text)\n",
    "            print(f\"Checking {header.text} ({link.css.select_one('td:nth-child(4)').text})\")\n",
    "            try:\n",
    "                tor.get(link.css.select_one('td:nth-child(4)').text, timeout=60)\n",
    "                ransomlook['Available'].append(True)\n",
    "            except:\n",
    "                ransomlook['Available'].append(False)\n",
    "\n",
    "ransomlook = pd.DataFrame(ransomlook)\n",
    "ransomlook['Available'] = ransomlook['Available'].astype('bool')\n",
    "ransomlook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072a0a393199352",
   "metadata": {},
   "source": [
    "# [Ransomfeed](https://ransomfeed.it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649b10c520be567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "ransomfeed = { 'Group': [], 'Link': [], 'Available': [], 'AvailableLabel': [] }\n",
    "ransomfeed_soup = bs4.BeautifulSoup(get('https://ransomfeed.it/stats.php?page=groups-stats', timeout=60).text)\n",
    "ransomfeed_soup = ransomfeed_soup.find('tbody')\n",
    "ransomfeed_soup = ransomfeed_soup.css.select('tr')\n",
    "\n",
    "for row in ransomfeed_soup:\n",
    "    name = row.css.select_one('a')\n",
    "    group_soup = bs4.BeautifulSoup(get(f\"https://ransomfeed.it{name.attrs['href']}\").text)\n",
    "    card = group_soup.css.select_one('.card:nth-child(3)')\n",
    "    if card is None:\n",
    "        continue\n",
    "    for ro in card.css.select('tr:not(:first-child)'):\n",
    "        ransomfeed['Group'].append(name.text)\n",
    "        ransomfeed['Link'].append(ro.css.select_one('td:nth-child(1)').text)\n",
    "        ransomfeed['AvailableLabel'].append('🟢' in ro.css.select_one('td:nth-child(3)').text)\n",
    "        print(f\"Checking {name.text} ({ro.css.select_one('td:nth-child(1)').text})\")\n",
    "        try:\n",
    "            tor.get(ro.css.select_one('td:nth-child(1)').text, timeout=60)\n",
    "            ransomfeed['Available'].append(True)\n",
    "        except:\n",
    "            ransomfeed['Available'].append(False)\n",
    "\n",
    "ransomfeed = pd.DataFrame(ransomfeed)\n",
    "ransomfeed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a273387e5d7acd5",
   "metadata": {},
   "source": [
    "# [ransomwarelive](https://www.ransomware.live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7dc69614b0eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "ransomwarelive = { 'Group': [], 'Link': [], 'Available': [], 'AvailableLabel': [] }\n",
    "ransomwarelive_soup = bs4.BeautifulSoup(get('https://www.ransomware.live/groups/', timeout=60).text)\n",
    "ransomwarelive_soup = ransomwarelive_soup.find('tbody')\n",
    "ransomwarelive_soup = ransomwarelive_soup.css.select('tr')\n",
    "\n",
    "for row in ransomwarelive_soup:\n",
    "    name = row.css.select_one('a')\n",
    "    group_soup = bs4.BeautifulSoup(get(f\"https://www.ransomware.live{name.attrs['href']}\").text, timeout=60)\n",
    "    card = group_soup.css.select_one('tbody')\n",
    "    if card is None:\n",
    "        continue\n",
    "    for ro in card.css.select('tr'):\n",
    "        ransomwarelive['Group'].append(name.text)\n",
    "        ransomwarelive['Link'].append(ro.css.select_one('td:nth-child(4)').text)\n",
    "        ransomwarelive['AvailableLabel'].append('🟢' in ro.css.select_one('td:nth-child(2)').text)\n",
    "        print(f\"Checking {name.text} ({ro.css.select_one('td:nth-child(4)').text})\")\n",
    "        try:\n",
    "            tor.get(ro.css.select_one('td:nth-child(4)').text, timeout=60)\n",
    "            ransomwarelive['Available'].append(True)\n",
    "        except:\n",
    "            ransomwarelive['Available'].append(False)\n",
    "\n",
    "ransomwarelive = pd.DataFrame(ransomfeed)\n",
    "ransomwarelive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caee72d5a3dffa",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Wie viel Prozent falsch online angezeigt?\n",
    "Wie viel Prozent der Posts kriegen wir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307721d15ef6ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e7fc51733daaac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:52:45.428350Z",
     "start_time": "2024-12-17T19:52:43.849271Z"
    }
   },
   "outputs": [],
   "source": [
    "from script.normalizer import normalize\n",
    "\n",
    "normalize(deepdarkcti, reddit2024, darknet, ransomwatch, ransomfind, ransomlook, ransomwarelive, ransomfeed)\n",
    "\n",
    "all_groups = pd.concat([\n",
    "    deepdarkcti,\n",
    "    reddit2024,\n",
    "    darknet,\n",
    "    ransomwatch,\n",
    "    ransomfind,\n",
    "    ransomlook,\n",
    "    ransomwarelive,\n",
    "    ransomfeed\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7212aa99f5fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fa372d6433d7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T10:22:25.490628Z",
     "start_time": "2024-11-12T10:22:24.724939Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tracked_status(only_active, indexer_dict: dict):\n",
    "    tracking_status = { 'Group': [] }\n",
    "    for i in indexer_dict.keys():\n",
    "        tracking_status[i] = []\n",
    "    \n",
    "    concatted = all_groups\n",
    "    if only_active:\n",
    "        concatted = concatted[concatted['Available']]\n",
    "    total = concatted['Group'].unique()\n",
    "\n",
    "    for i in indexer_dict.keys():\n",
    "        indexer = indexer_dict[i]\n",
    "        if only_active:\n",
    "            indexer = indexer[indexer['Available']]\n",
    "        for group in total:\n",
    "            tracking_status[i].append((indexer['Group'] == group).any())\n",
    "\n",
    "    for group in total:\n",
    "        tracking_status['Group'].append(group)\n",
    "    \n",
    "    return pd.DataFrame(tracking_status)\n",
    "\n",
    "indexers = {\n",
    "    'deepdarkcti': deepdarkcti,\n",
    "    'reddit2024': reddit2024,\n",
    "    'darknet': darknet,\n",
    "    'ransomwatch': ransomwatch,\n",
    "    'ransomfind': ransomfind,\n",
    "    'ransomlook': ransomlook,\n",
    "    'ransomwarelive': ransomwarelive,\n",
    "    'ransomfeed': ransomfeed\n",
    "}\n",
    "\n",
    "tracking_status_all = get_tracked_status(False, indexers)\n",
    "\n",
    "groups_all = tracking_status_all['Group'].count()\n",
    "relative_all = tracking_status_all.sum(numeric_only=True).transform(lambda x: x * 100 / groups_all)\n",
    "\n",
    "ax_all = relative_all.plot.barh(xlim=[0, 100])\n",
    "ax_all.bar_label(ax_all.containers[0], fmt=\"%.3g %%\")\n",
    "\n",
    "print(groups_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5525d061de6b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T10:25:09.856819Z",
     "start_time": "2024-11-13T10:25:09.769555Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "keywords = [\n",
    "    \"medical\",\n",
    "    \"hospital\",\n",
    "    \"clinic\",\n",
    "    \"insur\",\n",
    "    \"dent\",\n",
    "    \"patient\",\n",
    "    \"recover\",\n",
    "    \"doctor\",\n",
    "    \"nurs\",\n",
    "    \"health\",\n",
    "    \"facilit\",\n",
    "    \"care\",\n",
    "    \"lab\",\n",
    "    \"pediat\",\n",
    "    \"rehab\",\n",
    "    \"krank\",\n",
    "    \"mediz\",\n",
    "    \"gesund\",\n",
    "]\n",
    "\n",
    "with open(\"data/posts.json\", \"r\") as f:\n",
    "    posts = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(posts)\n",
    "\n",
    "filtered = df['post_title'].apply(lambda d: any(keyword in d.lower() for keyword in keywords))\n",
    "\n",
    "df = df[filtered]\n",
    "\n",
    "df['discovered'] = pd.to_datetime(df['discovered'])\n",
    "df['discovered'] = df['discovered'].dt.to_period('M')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb31997a3ab5b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:49:56.998497Z",
     "start_time": "2024-11-14T12:49:56.791888Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, to_datetime\n",
    "\n",
    "results_all = { 'Title': [], 'Group': [], 'Date': [] }\n",
    "results_medical = { 'Title': [], 'Group': [], 'Date': [] }\n",
    "for post in posts:\n",
    "    title = post['post_title'].lower()\n",
    "    results_all['Title'].append(post['post_title'])\n",
    "    results_all['Group'].append(post['group_name'])\n",
    "    results_all['Date'].append(post['discovered'])\n",
    "    for keyword in keywords:\n",
    "        if keyword in title:\n",
    "            results_medical['Title'].append(post['post_title'])\n",
    "            results_medical['Group'].append(post['group_name'])\n",
    "            results_medical['Date'].append(post['discovered'])\n",
    "            break\n",
    "\n",
    "df_all = DataFrame(results_all)\n",
    "\n",
    "df_all['Date'] = to_datetime(df_all['Date'])\n",
    "df_all['Month'] = df_all['Date'].dt.to_period('M')\n",
    "print(len(results_all['Title']))\n",
    "\n",
    "data_all = df_all['Month'].value_counts()\n",
    "\n",
    "df_medical = DataFrame(results_medical)\n",
    "\n",
    "df_medical['Date'] = to_datetime(df_medical['Date'])\n",
    "df_medical['Month'] = df_medical['Date'].dt.to_period('M')\n",
    "print(len(results_medical['Title']))\n",
    "\n",
    "\n",
    "data_medical = df_medical['Month'].value_counts()\n",
    "\n",
    "all = DataFrame({\n",
    "    'all': data_all,\n",
    "    'medical': data_medical,\n",
    "})\n",
    "all['part'] = all['medical'] / all['all']\n",
    "all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
